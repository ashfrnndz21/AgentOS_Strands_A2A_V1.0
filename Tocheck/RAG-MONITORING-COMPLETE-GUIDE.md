# ðŸ” Complete RAG Pipeline Monitoring Guide

## ðŸ“‹ How to See Document Processing Details

When you upload a PDF to the frontend, here are **5 ways** to monitor the chunking, embedding, and metadata processing:

### ðŸ–¥ï¸ **1. Frontend Real-Time Monitoring**

**In the Browser:**
1. Go to **Document Chat** page
2. Click **"Metadata & Chunks"** tab (new!)
3. Upload a document
4. Watch real-time processing logs
5. See detailed chunk breakdown

**What you'll see:**
- âœ… Document processing progress
- ðŸ“Š Number of chunks created
- ðŸ“„ Pages processed
- ðŸ¤– Model used for processing
- â±ï¸ Processing timestamps
- ðŸ” Individual chunk content and metadata

### ðŸ“Š **2. Metadata Panel (New Feature)**

**Location:** Document Chat â†’ Metadata & Chunks tab

**Shows:**
- **Overview Tab**: Total documents, chunks, vector stores
- **Documents Tab**: List of all processed documents with metadata
- **Chunks Tab**: Individual chunks with content preview

**Document Metadata Includes:**
```
ðŸ“„ Filename: document.pdf
ðŸ”¢ Chunks: 45 chunks created
ðŸ“– Pages: 12 pages processed  
ðŸ¤– Model: mistral
â° Processed: 2025-01-09 16:45:23
ðŸ’¾ Storage: ChromaDB + FastEmbed
ðŸ“ Size: 2.3 MB
```

**Chunk Details Include:**
```
âœ‚ï¸  Chunk 1 of 45
ðŸ“ Position: chars 0-1000
ðŸ“„ Page: 1
ðŸ“ Content: "This document discusses..."
ðŸ§® Vector: 384 dimensions
```

### ðŸ–¥ï¸ **3. Backend Real-Time Monitor**

**Run this script while uploading:**
```bash
python watch_rag_processing.py
```

**Shows live processing:**
```
[16:45:23] ðŸ“„ NEW DOCUMENT DETECTED!
   Documents: 0 â†’ 1
[16:45:24] âœ‚ï¸  NEW CHUNKS CREATED: +45
   Total chunks: 0 â†’ 45
   ðŸ“‹ Latest Document Details:
      - Filename: sample.pdf
      - Chunks: 45
      - Pages: 12
      - Model: mistral
      - Embeddings: fastembed
      - Vector DB: chroma
```

### ðŸ“Š **4. API Endpoints for Direct Inspection**

**Check RAG Status:**
```bash
curl http://localhost:8000/api/rag/status
```

**List All Documents:**
```bash
curl http://localhost:8000/api/rag/documents
```

**Get Document Chunks:**
```bash
curl http://localhost:8000/api/rag/documents/{document_id}/chunks
```

**Example Response:**
```json
{
  "status": "success",
  "document_id": "doc_abc123",
  "chunks": [
    {
      "chunk_id": "doc_abc123_chunk_0",
      "content": "This is the first chunk of text...",
      "metadata": {
        "document_id": "doc_abc123",
        "chunk_index": 0,
        "char_start": 0,
        "char_end": 1000,
        "page_number": 1
      }
    }
  ],
  "total_chunks": 45
}
```

### ðŸ” **5. Backend Logs (Terminal)**

**Watch backend terminal for detailed logs:**
```
INFO:__main__:[INFO] ðŸ“„ Processing document: sample.pdf
INFO:__main__:[INFO] ðŸ“– Extracted text from 12 pages
INFO:__main__:[INFO] âœ‚ï¸  Created 45 chunks with 200 char overlap
INFO:__main__:[INFO] ðŸ§® Generated embeddings using FastEmbed
INFO:__main__:[INFO] ðŸ’¾ Stored in ChromaDB vector database
INFO:__main__:[INFO] âœ… Document processing complete
```

## ðŸ”¬ **Detailed Processing Pipeline**

### **Step 1: Document Upload**
```
PDF File â†’ Backend â†’ Content Extraction
```
- File validation (type, size)
- PDF text extraction using PyPDF
- Content cleaning and preprocessing

### **Step 2: Text Chunking**
```
Raw Text â†’ LangChain Splitter â†’ Semantic Chunks
```
- **Chunk Size**: ~1000 characters
- **Overlap**: 200 characters between chunks
- **Smart Splitting**: Respects sentence boundaries
- **Metadata**: Position, page numbers, source info

### **Step 3: Embedding Generation**
```
Text Chunks â†’ FastEmbed â†’ 384D Vectors
```
- **Model**: BAAI/bge-small-en-v1.5
- **Dimensions**: 384 per chunk
- **Context**: 512 token limit
- **Speed**: ~100 chunks/second

### **Step 4: Vector Storage**
```
Embeddings â†’ ChromaDB â†’ Indexed Storage
```
- **Database**: ChromaDB (persistent)
- **Index**: Optimized for cosine similarity
- **Metadata**: Linked to original chunks
- **Search**: Sub-second retrieval

### **Step 5: Query Processing**
```
User Query â†’ Embedding â†’ Similarity Search â†’ Top-K Chunks
```
- **Query Embedding**: Same 384D space
- **Search**: Cosine similarity ranking
- **Retrieval**: Top 3-5 most relevant chunks
- **Context**: Assembled for AI generation

## ðŸŽ¯ **What to Look For**

### **Successful Processing Indicators:**
- âœ… Chunks created > 0
- âœ… Pages processed matches PDF pages
- âœ… Processing time < 30 seconds for typical docs
- âœ… No error messages in logs
- âœ… Vector store shows active

### **Chunking Quality Indicators:**
- ðŸ“ Chunk sizes between 500-1500 characters
- ðŸ”— Meaningful overlap between chunks
- ðŸ“„ Page numbers correctly tracked
- ðŸ“ Content preserves sentence structure

### **Performance Metrics:**
- âš¡ Processing: ~2-5 seconds per page
- ðŸ§® Embedding: ~100 chunks per second
- ðŸ’¾ Storage: Immediate indexing
- ðŸ” Retrieval: <100ms query response

## ðŸš€ **Try It Now!**

1. **Start monitoring:** `python watch_rag_processing.py`
2. **Open browser:** Go to Document Chat â†’ Metadata & Chunks
3. **Upload PDF:** Drag and drop a document
4. **Watch processing:** See real-time chunking details
5. **Explore chunks:** Click on documents to see individual chunks
6. **Test queries:** Ask questions and see which chunks are retrieved

The system provides complete visibility into every step of the RAG pipeline! ðŸŽ‰